{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![header](./data/header_banner.jpeg \"Header\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning vs. March Madness\n",
    "Authors: [Matthew Reinhart](https://www.linkedin.com/in/matthew-reinhart-1bb372173/), [Mendy Nemanow](https://www.linkedin.com/in/mendy-nemanow-2594ab225/), [Paul Lindquist](https://www.linkedin.com/in/paul-lindquist/), [TJ Bray](https://www.linkedin.com/in/thomas-tj-bray-24499354/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "Sports gambling is one of the fastest growing industries in the country, with states continuing to pass betting-friendly legislation and companies like DraftKings, FanDuel and BetMGM experiencing increased, year-over-year revenue. One of the premier sports betting events of the year is the NCAA college basketball postseason tournament, commonly known as *March Madness*.\n",
    "\n",
    "We target college basketball because of our domain knowledge and the talent disparity within the sport. In professional sports, the talent gap between the best and worst teams is very small. It's unusual to see NBA spreads greater than 10 points. In college basketball, this happens regularly. Teams are 25-point underdogs on a given night and that creates betting opportunity. There also tends to be more regular competition in college basketball. With only around 30 games in a season, teams don't have the luxury to take nights off like we see in an 82-game NBA season. And with constant effort comes more predictable outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Objective\n",
    "This project posits that we run a sports gambling company. We offer our customers advisory services during the busiest time of the sports year on events with the greatest amount of betting action.\n",
    "\n",
    "To maximize returns, we run a series of machine learning algorithms to model predictions for single games in the NCAA tournament. We pay particular focus to accurately predicting underdog team wins, as doing so yields higher payouts. Accuracy, and more specifically *predictive* accuracy, is paramount in selecting our models, as we strive to minimize risk for our customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "This project uses datasets from Kaggle's *[March Machine Learning Mania 2021](https://www.kaggle.com/c/ncaam-march-mania-2021/data)* competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "We set the win/loss outcome for the favored team as the binary target variable, with 1 equaling a win for the favored team and 0 equaling a win for the underdog. Rankings are assigned using the reputable KenPom ratings.\n",
    "\n",
    "We then use an iterative approach to build 6 predictive, classification models: Logistic Regression, K-Nearest Neighbors, Decision Tree, Random Forest, Bagging classifier and XGBoost. We utilize hyperparameter tuning, cross-validation and scoring to select the highest performing, predictive models. This approach is applied to regular season, postseason and cumulative postseason data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "After comparing metrics across all 6 of our models, the top 3 performers are Logistic Regression, XGBoost and Random Forest. While XGBoost and Logistic Regression yield the same accuracy score, we opt to go with latter because its standard deviation is half of that of XGBoost's.\n",
    "\n",
    "![img1](https://i.ibb.co/dGWBMhw/f.png)\n",
    "\n",
    "Our model consistently outperforms the baseline (i.e. only betting on favored teams) in postseason tournaments.\n",
    "\n",
    "![img2](https://i.ibb.co/3kbq72V/e.png)\n",
    "\n",
    "There's inherent value in correctly betting on underdogs, as that yields higher payouts. We give specific focus to those predictions to assess our model's performance.\n",
    "\n",
    "![img4](https://i.ibb.co/NSLBHBp/d.png)\n",
    "\n",
    "With a 71% mean accuracy score of correctly predicting underdogs, our model performs quite well.\n",
    "\n",
    "![img3](https://i.ibb.co/p37vTPr/c.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The results of our logistic regression model in the tournament are very strong:\n",
    "- Overall 78% mean accuracy score for single-game predictions\n",
    "- 71% mean accuracy score for underdog predictions\n",
    "\n",
    "As such, we recommend following the model's underdog predictions for the duration of the tournament. Doing so will help maximize returns.\n",
    "\n",
    "For next steps, we'd like to explore the following:\n",
    "- Integrate moneyline data to further identify value\n",
    "- Incorporate more player-specific data to predict how a player will perform on a given day\n",
    "- Look at adjusting bet sizing to implement risk-adjusted wagers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For More Information\n",
    "Please review our full analysis in our Jupyter Notebook or presentation deck.\n",
    "\n",
    "For additional questions, please contact [Matthew](https://www.linkedin.com/in/matthew-reinhart-1bb372173/), [Mendy](https://www.linkedin.com/in/mendy-nemanow-2594ab225/), [Paul](https://www.linkedin.com/in/paul-lindquist/) or [TJ](https://www.linkedin.com/in/thomas-tj-bray-24499354/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respository Structure\n",
    "```\n",
    "├── README.md                           <- The top-level README for reviewers of this project\n",
    "├── final_notebook.ipynb                <- Narrative documentation of analysis in Jupyter notebook\n",
    "├── project_presentation.pdf            <- PDF version of project presentation\n",
    "├── data                                <- Both sourced externally and generated from code\n",
    "└── images                              <- Both sourced externally and generated from code\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
